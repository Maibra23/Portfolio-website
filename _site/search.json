[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project portfolio",
    "section": "",
    "text": "Explore the world of information"
  },
  {
    "objectID": "index.html#my-data-journey",
    "href": "index.html#my-data-journey",
    "title": "Project portfolio",
    "section": "My Data Journey",
    "text": "My Data Journey\nWelcome! I’m Mustafa, and my journey in data analysis began with a fundamental curiosity: Why is some data complex to uncover, and how can simplifying this complexity change the narratives that reshape our everyday experiences?\nWhat if the image below wasn’t just a view of Earth at night, but a reflection of the complexity of data? Each light could be a piece of information, scattered and interconnected, waiting to tell a story. How much could we uncover just by taking a closer look? Data can feel overwhelming, like staring at all these lights for the first time, but once we start making sense of it, patterns and insights begin to emerge. What do you see in this image? What story would you start to tell?"
  },
  {
    "objectID": "index.html#over-the-last-couple-of-years-ive-worked-on",
    "href": "index.html#over-the-last-couple-of-years-ive-worked-on",
    "title": "Project portfolio",
    "section": "Over the last couple of years, I’ve worked on:",
    "text": "Over the last couple of years, I’ve worked on:\n\n\n\n\nCNN Model Project\n\n\n\n\n\n\nSurvival Analysis\n\n\n\n\n\n\nTime Series Analysis"
  },
  {
    "objectID": "index.html#learn-more-about-me",
    "href": "index.html#learn-more-about-me",
    "title": "Project portfolio",
    "section": "Learn More About Me",
    "text": "Learn More About Me\n\nMy Goals\nMy Education"
  },
  {
    "objectID": "projects/cnn_model.html",
    "href": "projects/cnn_model.html",
    "title": "CNN Model Project",
    "section": "",
    "text": "In this project, we build a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset using R, diverging from the common trend of using Python for machine learning. This CNN implementation serves as a crucial foundation before exploring more complex RNN models. The CIFAR-10 dataset contains 60,000 32x32 color images categorized into 10 classes, with 6,000 images per class. Our objective is to provide a systematic approach to constructing, training, and applying the model for image classification, setting up essential skills for advanced neural network architectures like RNN and LSTM. This could be considered a short tutorial that covers every step of the process, including dataset loading, model creation, training, and evaluation."
  },
  {
    "objectID": "projects/cnn_model.html#model-1-evaluation",
    "href": "projects/cnn_model.html#model-1-evaluation",
    "title": "CNN Model Project",
    "section": "3.1 Model 1 Evaluation",
    "text": "3.1 Model 1 Evaluation\nThe plot demonstrate the training results. The last part of the code represent the plot generated of the model performance during the training. By observing the plot, we detect a sign of overfitting. A situation where model performs exceptionally well on training data but poorly on new data. If the model’s performance on the validation set begins to drop while continuing to improve on the training set, then this is a clear indication of overfittning. Now, with this plot, we can adjust our current model to mitigate the overfitting issue.\n\n# Model 2\nmodel.2 &lt;- keras_model_sequential() %&gt;%\n\n# First conv layer\n   layer_conv_2d(filters=32, kernel_size = c(3, 3), padding=\"same\", input_shape = c(32, 32, 3), activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n\n# Second conv layer\n   layer_conv_2d(filters=32, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%\n   layer_dropout(0.2) %&gt;%\n\n# Third and fourth conv layer\n   layer_conv_2d(filters=64, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_conv_2d(filters=64, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%\n   layer_dropout(0.3) %&gt;%\n\n# Fifth and sixth conv layer\n   layer_conv_2d(filters=128, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_conv_2d(filters=128, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%\n   layer_dropout(0.4) %&gt;%\n\n# Flatten layer\n   layer_flatten() %&gt;%\n\n# Dense layers\n   layer_dense(units = 256, activation = 'relu') %&gt;%\n   layer_dense(units = 10, activation = 'softmax')\n\nmodel.2 %&gt;% summary()\n\nModel: \"sequential_1\"\n________________________________________________________________________________\n Layer (type)                  Output Shape               Param #    Trainable  \n================================================================================\n conv2d_9 (Conv2D)             (None, 32, 32, 32)         896        Y          \n batch_normalization_9 (Batch  (None, 32, 32, 32)         128        Y          \n Normalization)                                                                 \n conv2d_8 (Conv2D)             (None, 32, 32, 32)         9248       Y          \n batch_normalization_8 (Batch  (None, 32, 32, 32)         128        Y          \n Normalization)                                                                 \n max_pooling2d_4 (MaxPooling2  (None, 16, 16, 32)         0          Y          \n D)                                                                             \n dropout_4 (Dropout)           (None, 16, 16, 32)         0          Y          \n conv2d_7 (Conv2D)             (None, 16, 16, 64)         18496      Y          \n batch_normalization_7 (Batch  (None, 16, 16, 64)         256        Y          \n Normalization)                                                                 \n conv2d_6 (Conv2D)             (None, 16, 16, 64)         36928      Y          \n batch_normalization_6 (Batch  (None, 16, 16, 64)         256        Y          \n Normalization)                                                                 \n max_pooling2d_3 (MaxPooling2  (None, 8, 8, 64)           0          Y          \n D)                                                                             \n dropout_3 (Dropout)           (None, 8, 8, 64)           0          Y          \n conv2d_5 (Conv2D)             (None, 8, 8, 128)          73856      Y          \n batch_normalization_5 (Batch  (None, 8, 8, 128)          512        Y          \n Normalization)                                                                 \n conv2d_4 (Conv2D)             (None, 8, 8, 128)          147584     Y          \n batch_normalization_4 (Batch  (None, 8, 8, 128)          512        Y          \n Normalization)                                                                 \n max_pooling2d_2 (MaxPooling2  (None, 4, 4, 128)          0          Y          \n D)                                                                             \n dropout_2 (Dropout)           (None, 4, 4, 128)          0          Y          \n flatten_1 (Flatten)           (None, 2048)               0          Y          \n dense_3 (Dense)               (None, 256)                524544     Y          \n dense_2 (Dense)               (None, 10)                 2570       Y          \n================================================================================\nTotal params: 815914 (3.11 MB)\nTrainable params: 815018 (3.11 MB)\nNon-trainable params: 896 (3.50 KB)\n________________________________________________________________________________\n\n\nSince we observed overfitting issues in the plot for our initial model, we decided to adjust the capacity of our model, which we called model 2. We increased the complexity of the model by adding more convolutional layers and increasing the number of filters in the later layers. This approach was taken to potentially improve the model’s ability to learn more complex features from the data. However, recognizing that deeper networks can be prone to memorizing patterns rather than learning generalizable features, we also implemented additional measures to combat potential overfitting. Specifically, we added more dropout layers throughout the network. These dropout layers act as a form of regularization, randomly deactivating a portion of neurons during training, which helps prevent the model from relying too heavily on any specific features.\nOur main goal with model 2 is to get better accuracy than the first model, while still avoiding overfitting. We’re trying to find a balance between making the model smart enough to learn complex patterns, but not so complex that it just memorizes the training data.\n\n# Compile model.2\nmodel.2 %&gt;% compile(\n  optimizer = \"adam\",\n  loss = 'categorical_crossentropy',\n  metrics = 'accuracy'\n)\n\nThe compiling set up for the model remains the same as the previous model, and we intent to keep it consistent across this project. Yet, we may adjust it if needed to optimize the model performance. Considering our computational limitation, we believe this set up is the optimal one between learning speed and stability. Additionally, by maintaining this consistency, we can more effectively compare the results of different model architectures.\n\n# Train Model 2\ntrain.2 = model.2 %&gt;% fit(\n  t.images, t.labels,\n  epochs = 50,\n  batch_size = 32,\n  validation_data = list(test.images, test.labels),\n  shuffle = TRUE\n)\n\n# Saving\npng(\"model_2_training_plot2.png\")\nplot(train.2)\ndev.off()\n\nsave_model_hdf5(model.2, filepath = \"cnn_model_2.h5\")\n\nevaluation_result = model.2 %&gt;% evaluate(test.images, test.labels)\nsaveRDS(evaluation_result, file = \"model_2_evaluation2.rds\")\n\nWe are taking the same steps as in the initial model training as it align with our computation resource but also we want to ensure consistency and comparability across this project. Despite the architectural changes in model 2, maintaining these consistent training procedures allows us to isolate the effects of our model modifications. Any differences in performance can then be more confidently attributed to the changes in model structure rather than variations in the training process.\n\n# Uploading \nknitr::include_graphics(\"images/model_2_training_plot.png\")\n\n\n\nevaluation_result = readRDS(\"images/model_2_evaluation2.rds\")\nprint(evaluation_result)\n\n    loss accuracy \n  0.5543   0.8469"
  },
  {
    "objectID": "projects/cnn_model.html#model-2-evaluation",
    "href": "projects/cnn_model.html#model-2-evaluation",
    "title": "CNN Model Project",
    "section": "3.2 Model 2 Evaluation",
    "text": "3.2 Model 2 Evaluation\nThe plot here are the results of model 2 training, and comparing it to model 1 it reveals some notable contrasts. In the case of model 1, we observe signs of overfitting. We can see that the training loss decreases steadily, while the validation loss begins to rise after an initial dip. At the same time, training accuracy climbs to its highest level, in the mean time validation accuracy stagnates and even declines slightly, signaling poor generalization. This type of behavior often suggests that the model relies on memorization, basically memorizing training data rather than learning patterns that extend to unseen data. The result of evaluation metrics back this up, with model 1 achieving a validation loss of 0.798 and an accuracy of 81.73%, reflecting its limited effectiveness on new data.\nModel 2, however, shows a slight improvement, specifically if we observe the decreased gap in the accuracy part between the two plots. Training and validation losses both decrease smoothly, with validation loss stabilizing at a lower point. Validation accuracy also shows consistent growth, closely tracking training accuracy, which signals stronger generalization. The evaluation results confirm these gains, as model 2 achieves a reduced validation loss of 0.554 and a higher accuracy of 84.6%. Regularization techniques, like dropout, were key to this improvement. As a result, model 2 is not only better at generalizing but also more dependable for real-world tasks.\nAlthough model 2 shows significant improvements over model 1, there is still room for further enhancement.The validation loss, while reduced, remains higher than the training loss, indicating a potential gap in generalization. With that in mind, There is different techniques that could be applied to refine our current model. We could say that we need to improve the model, and the best approach we came up with was implementing data augmentation to artificially expand the training data and its diversity.\n\n# Now adding Data Augmentation for model.3\n\n# Data augmentation prep\ndatagen = image_data_generator(\n  rotation_range = 30,\n  width_shift_range = 0.1,  \n  height_shift_range = 0.1, \n  shear_range = 0.2,        \n  zoom_range = 0.2,        \n  horizontal_flip = TRUE,   \n  fill_mode = \"nearest\" )\n\n# data augmentation generator to training data\ndatagen %&gt;% fit_image_data_generator(t.images)\n\nData augmentation is an approach that is widely used to create new versions of already existing images by manipulating their features. Simply put, it involves applying changes to existing images through techniques like rotating, flipping, cropping, or adjusting brightness. This can be beneficial because it helps the model learn better by exposing it to different variations of the images without needing more real images. Our believe is that this could improve the model’s performance, especially when we have limited data.\n\n# New Model (model.3) with the same architecture as model.2\nmodel.3 &lt;- keras_model_sequential() %&gt;%\n   \n# First conv layer\n   layer_conv_2d(filters=32, kernel_size = c(3, 3), padding=\"same\", input_shape = c(32, 32, 3), activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n\n# Second conv layer\n   layer_conv_2d(filters=32, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%\n   layer_dropout(0.25) %&gt;%\n\n# Third and fourth conv layer\n   layer_conv_2d(filters=64, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_conv_2d(filters=64, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%\n   layer_dropout(0.35) %&gt;%\n\n# Fifth and sixth conv layer\n   layer_conv_2d(filters=128, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_conv_2d(filters=128, kernel_size = c(3, 3), padding=\"same\", activation = 'relu') %&gt;%\n   layer_batch_normalization() %&gt;%\n   layer_max_pooling_2d(pool_size = c(2,2)) %&gt;%\n   layer_dropout(0.45) %&gt;%\n\n# Flatten layer\n   layer_flatten() %&gt;%\n\n# Dense layers\n   layer_dense(units = 256, activation = 'relu') %&gt;%\n   layer_dense(units = 10, activation = 'softmax')\n\nmodel.3 %&gt;% summary()\n\nModel: \"sequential_2\"\n________________________________________________________________________________\n Layer (type)                  Output Shape               Param #    Trainable  \n================================================================================\n conv2d_15 (Conv2D)            (None, 32, 32, 32)         896        Y          \n batch_normalization_15 (Batc  (None, 32, 32, 32)         128        Y          \n hNormalization)                                                                \n conv2d_14 (Conv2D)            (None, 32, 32, 32)         9248       Y          \n batch_normalization_14 (Batc  (None, 32, 32, 32)         128        Y          \n hNormalization)                                                                \n max_pooling2d_7 (MaxPooling2  (None, 16, 16, 32)         0          Y          \n D)                                                                             \n dropout_7 (Dropout)           (None, 16, 16, 32)         0          Y          \n conv2d_13 (Conv2D)            (None, 16, 16, 64)         18496      Y          \n batch_normalization_13 (Batc  (None, 16, 16, 64)         256        Y          \n hNormalization)                                                                \n conv2d_12 (Conv2D)            (None, 16, 16, 64)         36928      Y          \n batch_normalization_12 (Batc  (None, 16, 16, 64)         256        Y          \n hNormalization)                                                                \n max_pooling2d_6 (MaxPooling2  (None, 8, 8, 64)           0          Y          \n D)                                                                             \n dropout_6 (Dropout)           (None, 8, 8, 64)           0          Y          \n conv2d_11 (Conv2D)            (None, 8, 8, 128)          73856      Y          \n batch_normalization_11 (Batc  (None, 8, 8, 128)          512        Y          \n hNormalization)                                                                \n conv2d_10 (Conv2D)            (None, 8, 8, 128)          147584     Y          \n batch_normalization_10 (Batc  (None, 8, 8, 128)          512        Y          \n hNormalization)                                                                \n max_pooling2d_5 (MaxPooling2  (None, 4, 4, 128)          0          Y          \n D)                                                                             \n dropout_5 (Dropout)           (None, 4, 4, 128)          0          Y          \n flatten_2 (Flatten)           (None, 2048)               0          Y          \n dense_5 (Dense)               (None, 256)                524544     Y          \n dense_4 (Dense)               (None, 10)                 2570       Y          \n================================================================================\nTotal params: 815914 (3.11 MB)\nTrainable params: 815018 (3.11 MB)\nNon-trainable params: 896 (3.50 KB)\n________________________________________________________________________________\n\n\nTo improve our model further, we named this new version model 3 for simplicity reasons. This model maintains the same design as model 2, just to be able to implement the data augmentation technique to improve the models performance. By keeping the architecture identical to model 2, we can directly observe the impact of data augmentation on the model’s ability to learn and generalize. But the implementation of data augmentation do not happen until the training phase.\n\n# Compile model.3 (same as model.2)\nmodel.3 %&gt;% compile(\n  optimizer = \"adam\",\n  loss = 'categorical_crossentropy',\n  metrics = 'accuracy'\n)\n\nThe compilation process for this part is identical to that of Model 2. We intentionally maintained the same compilation settings to make sure a fair comparison between the two models. This will keep the architecture and compilation parameters consistent, we can more accurately observe and analyze any differences in performance.\n\n# Train Model 3 with augmented data\ngenerator = flow_images_from_data(t.images, t.labels, datagen, batch_size = 32)\ntrain.3 = model.3 %&gt;% fit(\n  generator,\n  steps_per_epoch = as.integer(nrow(t.images) / 32),\n  epochs = 50,\n  validation_data = list(test.images, test.labels),\n  shuffle = TRUE\n)\n\n# Saving\npng(\"model_3_training_plot3.png\")\nplot(train.3)\ndev.off()\n\nsave_model_hdf5(model.3, filepath = \"cnn_model_3.h5\")\n\n# Saving the Results\nevaluation_result =  model.3 %&gt;% evaluate(test.images, test.labels)\nsaveRDS(evaluation_result, file = \"model_3_evaluation3.rds\")\n\nIn this script, we train model 3 with augmented data to improve the model generalization capability. This can be achieved by first creating a data generator that applies real-time augmentations to the input images (t.images) and their corresponding labels (t.labels) during training, and then feeding the augmented data directly into the model. Similarly to the previous set up, the model trains for 50 epochs in batches of 32, with validation data tracking its performance. A plot of the training progress is saved as model_3_training_plot3.png, and the trained model is stored in HDF5 format (cnn_model_3.h5) for later use.\n\n# The results for Model 3\nknitr::include_graphics(\"images/model_3_training_plot3.png\")\n\n\n\n# Load the Saved Evaluation Result\nevaluation_result &lt;- readRDS(\"images/model_3_evaluation3.rds\")\nprint(evaluation_result)\n\n    loss accuracy \n 0.47224  0.86223"
  },
  {
    "objectID": "projects/cnn_model.html#model-3-evaluation",
    "href": "projects/cnn_model.html#model-3-evaluation",
    "title": "CNN Model Project",
    "section": "3.3 Model 3 Evaluation",
    "text": "3.3 Model 3 Evaluation\nThe results of Model 3 training are illustrated in this plot. The plot shows clear progress, especially when compared to the plot of Model 2. Training and validation losses decrease consistently, with validation loss stabilizing at a noticeably lower value. Validation accuracy steadily improves and aligns more closely with training accuracy, reflecting stronger generalization. The evaluation results for Model 3 further emphasize these gains, achieving a validation loss of 0.4722 and a higher accuracy of 86.23%, compared to Model 2’s accuracy of 84.6%%. These improvements are largely due to the introduction of data augmentation, which diversified the dataset and allowed the model to better handle unseen data.\nThere are several ways to further optimize the model and enhance its performance. One commonly used approach is fine-tuning the hyperparameters. This is a process that mostly involves experimenting with different aspects of the learning process, such as adjusting the learning rate, modifying the number of epochs, or testing various batch sizes to find the best configuration. For example, using a smaller learning rate allows the model to take smaller, more precise steps toward an optimal solution, reducing the risk of missing key patterns. On the other hand, a larger learning rate can speed up training but may overshoot ideal values, leading to sub-optimal results. Similarly, adjusting the number of epochs can help the model learn more thoroughly, while experimenting with batch sizes affects computational efficiency and gradient stability.\nWe believe these strategies are valuable if our main focus lies in optimizing our CNN model, but they require careful experimentation and additional resources that we currently do not possess. Unfortunately, this falls beyond the scope of the current project. However, these methods remain valuable options for future refinement if more time or resources become available."
  },
  {
    "objectID": "projects/survival_analysis.html",
    "href": "projects/survival_analysis.html",
    "title": "Project Coming Soon",
    "section": "",
    "text": "Project Coming Soon\n\nThe project will be available shortly—stay tuned for updates."
  },
  {
    "objectID": "projects/survival_analysis.html#project-coming-soon",
    "href": "projects/survival_analysis.html#project-coming-soon",
    "title": "Coming Soon",
    "section": "",
    "text": "The project will be available shortly—stay tuned for updates."
  },
  {
    "objectID": "projects/time_series.html",
    "href": "projects/time_series.html",
    "title": "Project Coming Soon",
    "section": "",
    "text": "Project Coming Soon\n\nThe project will be available shortly—stay tuned for updates."
  }
]
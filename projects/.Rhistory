# Uploading  libraries
library(pacman)
p_load(tidyverse, rio, mice, corrr, summarytools, caret, naniar, broom, knitr, kableExtra, pROC, DALEX, modelsummary,ggtext,shapr,DT, shinydashboard,shiny,plotly, PRROC, rsconnect)
data_car = import("/Users/Brook/Downloads/Car_Insurance_Claim.csv")
head(data_car, 5)
# Detailed summary of the missing values, counts and percentage, data type of the predictors
dfSummary(data_car)
# Dropping POSTAL_CODE and ID Variable
data_car = data_car[, c(-1, -13)]
# Visuals over missing values in bar plot
gg_miss_var(data_car) + geom_col(aes(y = n_miss, fill = n_miss > 0), color = "black", linewidth = 0.3) +  labs(subtitle = "CREDIT_SCORE and ANNUAL_MILEAGE have missing values (~10%)"
) +
theme_classic(base_size = 12)
# Imputing, using median
data_car  =  data_car %>%
mutate(
CREDIT_SCORE = ifelse(is.na(CREDIT_SCORE), median(CREDIT_SCORE, na.rm = TRUE), CREDIT_SCORE),
ANNUAL_MILEAGE = ifelse(is.na(ANNUAL_MILEAGE), median(ANNUAL_MILEAGE, na.rm = TRUE), ANNUAL_MILEAGE) )
# Checking if there's missing values in each variable
colSums(is.na(data_car))
numeric_var = c("PAST_ACCIDENTS", "SPEEDING_VIOLATIONS", "DUIS", "ANNUAL_MILEAGE")
# Density distributions for all relevant variables
distribution_fig = ggplot(data_car %>% pivot_longer(all_of(numeric_var)), aes(value, fill = name)) +
geom_density(alpha = 0.6) +
facet_wrap(~name, scales = "free", ncol = 2) +
labs(
title = "Distribution of Key Variables (Before Capping)",
subtitle = "Right-skewed distributions with extreme values (e.g., 22 speeding violations)"
) +
theme_classic() +
theme(legend.position = "none")
distribution_fig
# Capping function with thresholds
cap_custom = function(x, variable_n) {
threshold = case_when(
variable_n == "DUIS" ~ 3,
variable_n == "PAST_ACCIDENTS" ~ 4,
variable_n == "SPEEDING_VIOLATIONS" ~ 6,
TRUE ~ max(x, na.rm = TRUE)  # while no cap for the other variables
)
pmin(x, threshold)
}
# Then applying it on the dataset
data_car = data_car %>%
mutate(
DUIS = cap_custom(DUIS, "DUIS"),
PAST_ACCIDENTS = cap_custom(PAST_ACCIDENTS, "PAST_ACCIDENTS"),
SPEEDING_VIOLATIONS = cap_custom(SPEEDING_VIOLATIONS, "SPEEDING_VIOLATIONS")
)
# Distribution figure after capping
ggplot(data_car %>%
pivot_longer(c(DUIS, PAST_ACCIDENTS, SPEEDING_VIOLATIONS)),
aes(value, fill = name)) +
geom_density(alpha = 0.6) +
facet_wrap(~name, scales = "free", ncol = 3) +
labs(
title = "Distributions After Threshold Capping",
subtitle = "DUIS ≤2 | Accidents ≤4 | Speeding Violations ≤6"
) +
theme_classic() +
theme(legend.position = "none")
# Plot class distribution
class_dist = ggplot(data_car, aes(x = factor(OUTCOME), fill = factor(OUTCOME))) +
geom_bar() +
scale_fill_manual(values = c("blue", "red")) +
labs(
title = "Class Distribution of Insurance Claims",
x = "Claim Status (0 = No Claim, 1 = Claim)",
y = "Count",
fill = "Outcome"
) +
theme_classic() +
theme(legend.position = "none")
class_dist
# we define and test diff weights,  1.5 - 2.5
weights_to_test = seq(1.5, 2.5, by = 0.1)
# Store
results = data.frame(weight = weights_to_test, f_score = numeric(length(weights_to_test)))
# Loop and then evaluate F-scores
for (i in seq_along(weights_to_test)) {
model = glm(
OUTCOME ~ .,
data = data_car,
family = "binomial",
weights = ifelse(OUTCOME == 1, weights_to_test[i], 1)
)
predictions = ifelse(predict(model, type = "response") > 0.5, 1, 0)
cm = confusionMatrix(factor(predictions, levels = c(0, 1)), factor(data_car$OUTCOME, levels = c(0, 1)))
results$f_score[i] = cm$byClass["F1"]
}
# Selecting the optimal weight with maximum F-score
optimal_weight = results$weight[which.max(results$f_score)]
optimal_f1 = max(results$f_score)
# Plot results with highlighted optimal weight
ggplot(results, aes(weight, f_score)) +
geom_line(color = "black") +
geom_point(color = "orange") +
geom_point(data = results[which.max(results$f_score), ], aes(weight, f_score),
color = "red", size = 4) +
labs(
title = "Optimal Weight for Class Balancing",
x = "Weight for Claims (OUTCOME=1)",
y = "F-score"
) +
theme_classic()
# Turning categorical variables to factors
data_car = data_car %>%
mutate(
AGE = factor(AGE, levels = c("16-25", "26-39", "40-64", "65+")),
GENDER = factor(GENDER, levels = c("female", "male")),
RACE = factor(RACE, levels = c("majority", "minority")),
DRIVING_EXPERIENCE = factor(DRIVING_EXPERIENCE,
levels = c("0-9y", "10-19y", "20-29y", "30y+")),
EDUCATION = factor(EDUCATION, levels = c("none", "high school", "university")),
INCOME = factor(INCOME, levels = c("poverty", "working class", "middle class", "upper class")),
VEHICLE_YEAR = factor(VEHICLE_YEAR, levels = c("before 2015", "after 2015")),
VEHICLE_TYPE = factor(VEHICLE_TYPE, levels = c("sedan", "sports car")),
MARRIED = factor(MARRIED, levels = c(0, 1), labels = c("No", "Yes")),
CHILDREN = factor(CHILDREN, levels = c(0, 1), labels = c("No", "Yes")),
VEHICLE_OWNERSHIP = factor(VEHICLE_OWNERSHIP, levels = c(0, 1), labels = c("No", "Yes")),
OUTCOME = factor(OUTCOME, levels = c(0, 1))
)
data_car$ANNUAL_MILEAGE = data_car$ANNUAL_MILEAGE / 1000
# data shuffling and splitting 70/30
set.seed(987)
shu_data = data_car[sample(nrow(data_car)), ]
train_data = shu_data[1:7000, ]
test_data = shu_data[7001:10000, ]
# Final Model (Training Data)
final_model = glm(
OUTCOME ~ AGE + GENDER + RACE + DRIVING_EXPERIENCE + EDUCATION + INCOME +
CREDIT_SCORE + VEHICLE_OWNERSHIP + VEHICLE_YEAR + MARRIED + CHILDREN +
ANNUAL_MILEAGE + VEHICLE_TYPE + SPEEDING_VIOLATIONS + DUIS + PAST_ACCIDENTS +
AGE:VEHICLE_TYPE + PAST_ACCIDENTS:SPEEDING_VIOLATIONS,
data = train_data,
family = "binomial",
weights = ifelse(OUTCOME == 1, optimal_weight, 1)
)
# summary
modelsummary(final_model, output = "markdown", stars = T)
# plot Risk driver vs. risk reducer predictors. Odds
model_summary = tidy(final_model)
odds_table = data.frame(
Predictor = names(exp(coef(final_model))),
Odds_Ratio = round(exp(coef(final_model)), 2),
p_value = model_summary$p.value
) %>%
filter(Predictor != "(Intercept)") %>%
mutate(
Effect_Type = ifelse(Odds_Ratio > 1, "Risk Driver", "Risk Reducer"),
Predictor_Label = ifelse(
p_value < 0.1,
paste0("<b>", Predictor, "</b>"),  # Bold text for p < 0.1
Predictor
),
Odds_Label = case_when(
p_value < 0.01 ~ paste0(Odds_Ratio, "***"),
p_value < 0.05 ~ paste0(Odds_Ratio, "**"),
p_value < 0.1 ~ paste0(Odds_Ratio, "*"),
TRUE ~ as.character(Odds_Ratio)
)
) %>%
arrange(desc(Odds_Ratio))
odds_plot = ggplot(odds_table, aes(x = reorder(Predictor_Label, Odds_Ratio), y = Odds_Ratio, fill = Effect_Type)) +
geom_col(alpha = 0.8) +
geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
geom_text(aes(label = Odds_Label), hjust = -0.2, size = 3.5) +
coord_flip() +
scale_fill_manual(values = c("Risk Driver" = "#E74C3C", "Risk Reducer" = "#2ECC71")) +
labs(
title = "All Predictors: Significant Risk Drivers/Reducers ",
subtitle = "Odds Ratio > 1 = Higher Risk | * = p < 0.1, ** = p < 0.05, *** = p < 0.01",
x = "Predictor",
y = "Odds Ratio (Reference = 1)",
fill = "Effect Type"
) +
theme_classic() +
theme(
legend.position = "bottom",
axis.text.y = element_markdown(size = 10, color = "black"),
plot.margin = margin(20, 100, 20, 20)
)
odds_plot
explainer = DALEX::explain(
model = final_model,
data  = as.data.frame(train_data)[ , setdiff(names(train_data), "OUTCOME") ],
# Convert factor to 0/1 on the fly:
y     = as.numeric(train_data$OUTCOME) - 1,
# Default predict_function will return log-odds; we want probabilities:
predict_function = function(m, newdata) {
predict(m, newdata = newdata, type = "response")
},
label = "Logistic Model"
)
shap_values = predict_parts(
explainer,
new_observation = train_data[1:100, ],
type            = "shap",
B               = 100
)
shap_aggregated = shap_values %>%
group_by(variable) %>%
summarize(mean_abs_shap = mean(abs(contribution)), .groups = "drop") %>%
arrange(desc(mean_abs_shap))
#
ggplot(shap_aggregated, aes(
x = reorder(variable, mean_abs_shap),
y = mean_abs_shap
)) +
geom_col(fill = "#2F4F4F", width = 0.7) +
coord_flip() +
labs(
title    = "Global Feature Importance: SHAP Values",
subtitle = "Top Drivers of Insurance Claim Predictions",
x        = "Predictors",
y        = "Mean |SHAP Contribution|"
) +
theme_classic() +
theme(
plot.title    = element_text(face = "bold", size = 14),
axis.text.y   = element_text(size = 10)
)
# Generate predictions on test data
test_pred_prob = predict(final_model, newdata = test_data, type = "response")
test_pred_class = ifelse(test_pred_prob > 0.5, 1, 0)  # Threshold = 0.5
# ROC-AUC
roc_curve = roc(test_data$OUTCOME, test_pred_prob)
auc_value = auc(roc_curve)
roc_curve
# Plot ROC Curve
plot(roc_curve, main = "ROC Curve (Test Data)", col = "#2F4F4F", print.auc = TRUE)
